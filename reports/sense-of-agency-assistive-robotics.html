
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Understanding Sense of Agency in Assistive Robotics</title><style>
/* cspell:disable-file */
/* no ai usage: html files were exported from my previous notion website and modified by me for styling and proper image retrieving */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 0 auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

/* Override strong tags inside headings to maintain consistent weight */
h1 strong,
h2 strong,
h3 strong {
	font-weight: 600;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 10px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.callout img.notion-static-icon {
	width: 1em;
	height: 1em;
}

.callout p {
	margin: 0;
}

.callout h1,
.callout h2,
.callout h3 {
	margin: 0 0 0.6rem;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", "Noto Sans Arabic", "Noto Sans Hebrew", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", "Noto Sans Arabic", "Noto Sans Hebrew", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", "Noto Sans Arabic", "Noto Sans Hebrew", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", "Noto Sans Arabic", "Noto Sans Hebrew", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", "Noto Sans Arabic", "Noto Sans Hebrew", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.highlight-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.highlight-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.highlight-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.highlight-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.highlight-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.highlight-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(42, 28, 0, 0.07);
}
.highlight-brown_background {
	background: rgba(139, 46, 0, 0.086);
}
.highlight-orange_background {
	background: rgba(224, 101, 1, 0.129);
}
.highlight-yellow_background {
	background: rgba(211, 168, 0, 0.137);
}
.highlight-teal_background {
	background: rgba(0, 100, 45, 0.09);
}
.highlight-blue_background {
	background: rgba(0, 124, 215, 0.094);
}
.highlight-purple_background {
	background: rgba(102, 0, 178, 0.078);
}
.highlight-pink_background {
	background: rgba(197, 0, 93, 0.086);
}
.highlight-red_background {
	background: rgba(223, 22, 0, 0.094);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.block-color-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.block-color-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.block-color-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.block-color-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.block-color-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.block-color-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(229, 242, 252, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 118, 217, 0.203); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="25b36fd4-09d8-81df-bc3d-c83861220e37" class="page sans"><header><img class="page-cover-image" src="images/project3.png" style="object-position:center 50%"/><h1 class="page-title" dir="auto">Understanding Sense of Agency in Assistive Robotics</h1><p class="page-description" dir="auto"></p><table class="properties"><tbody></tbody></table></header><div class="page-body"><div style="display:contents" dir="auto"><h1 id="27d36fd4-09d8-80f3-aed2-c81f3482e159" class=""><mark class="highlight-orange">Challenge</mark></h1></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-809c-8c36-dfbe75ee2b6c" class="">When people think of a robot helping someone, they usually imagine speed and perfection. Most robotics systems are designed that way: to be as efficient as possible. But in the world of assistive robotics, where the device becomes an extension of a person, focusing only on speed can actually break the user experience.</p></div><div style="display:contents" dir="auto"><p id="28236fd4-09d8-800d-8ce9-e1df15050575" class="">
</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80e4-8384-eff74176384b" class="">This project grew out of a core question: is the most efficient robot also the most helpful robot? We found that if the robot takes over too much of the user’s desired actions, the user loses their sense of agency, SoA, the feeling of being in control of one’s own actions. This paradigm is rarely studied in assistive robotics, and the result of that is most research being focused on designing a task optimal, fully autonomous robot system. Previous studies have shown that when people don’t feel a strong SoA over their device, the devices often face misuse or abandonment.</p></div><div style="display:contents" dir="auto"><p id="28236fd4-09d8-8059-bc60-dd27adce7c7b" class="">
</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-808e-9b63-fea5ff740490" class="">I’m serving as an undergraduate researcher in this project, led by PhD student Maggie Collier at the <a href="https://harplab.github.io/harplab.deploy/">HARP</a> lab, looks into this tension. We’re not trying to replace the user when developing assistive robotic devices, we’re trying to build a trusted partner that serves as an extension of the user.</p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8051-9fb5-d7d13d8ad8b3" class="">
</p></div><div style="display:contents" dir="auto"><hr id="28136fd4-09d8-8033-b289-d3e56284d58a"/></div><div style="display:contents" dir="auto"><h1 id="27d36fd4-09d8-80db-a6a7-f0e7b6e4928f" class=""><mark class="highlight-orange">Research Questions</mark></h1></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80bf-9001-e09bab0281df" class="">This project is guided by three research questions:</p></div><div style="display:contents" dir="auto"><ol type="1" id="27d36fd4-09d8-80f9-91a2-c128f4d61756" class="numbered-list" start="1"><li>How do we define and develop an understanding of the subjective sense of agency experience among users in the context of assistive robotics?</li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="27d36fd4-09d8-80d6-b7dd-d17ee45ac677" class="numbered-list" start="2"><li>How do we develop measures of sense of agency that we can compute in real time in assistive robotics settings?</li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="27d36fd4-09d8-8078-9f16-f3c9a370ee01" class="numbered-list" start="3"><li>Does the disagreement between the robot&#x27;s and the user&#x27;s respective control signals have an effect on user sense of agency? If so, how can we use this disagreement to predict user sense of agency?</li></ol></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8003-b7be-f1288eb92723" class="">
</p></div><div style="display:contents" dir="auto"><p id="28136fd4-09d8-8084-a336-f3d72fc511f3" class="">The first two questions aim to establish a connection to a foundational sense of agency theory and the general mission of our work, while the final question is the core hypothesis of our specific study, which is still in progress. Disagreement, which we’ll later define, is more particularly the angle disagreement between the vector of the user’s input and the robot’s input. </p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8002-9c5b-f7971a76af7e" class="">
</p></div><div style="display:contents" dir="auto"><hr id="28136fd4-09d8-80db-a0ca-df4672c9bdc4"/></div><div style="display:contents" dir="auto"><h1 id="27d36fd4-09d8-809e-8e9b-fce9261c636a" class=""><mark class="highlight-orange">Background</mark></h1></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-8000-85b4-e6599b438ffc" class="">Shared Autonomy</h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8026-871b-db0f8d8f5b8f" class="">Shared autonomy is a collaborative control paradigm where both the human user and the robot&#x27;s intelligence contribute simultaneously to the final movement command. Instead of the robot being fully manual (tele-operated) or fully automated, the system merges the user&#x27;s input with the robot&#x27;s computed optimal path to execute a smooth motion from the starting point to the end goal. From an efficiency standpoint, the purpose of shared autonomy is to maximize user effectiveness while reducing the physical effort required. However, we’d like to explore the effect of shared autonomy on sense of agency, and at which point is it intrusive rather than helpful. </p></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-8056-b973-e7a93c7b6d77" class="">The Comparator Model of SoA</h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80b0-a140-e0d25f8c133d" class="">The prevailing theory of SoA is the comparator model. This model posits that a person determines if they were in control by comparing their expected outcome of an action with the actual outcome. For example, when a user presses a button to move the arm and the robot instantly corrects or finishes the move for them, ignoring their movements to go left when it calculates forward to be the shorter path, the user feels less command over the robot. On the other hand, when the expectation matches the reality, agency is high.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80f1-93d3-f41b99e6d0c3" class="">In shared autonomy, the robot&#x27;s help could create a mismatch between the user&#x27;s intended action and the robot&#x27;s final movement, threatening the comparator model&#x27;s required match and potentially harming SoA.</p></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-80bd-99fe-f35a2fbba039" class="">Quantifying this Trade-Off with <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span><span>﻿</span></span></h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8045-bd27-e9770ca9a0d8" class="">We use a formal definition of shared autonomy to define this mismatch/disagreement. The robot&#x27;s final movement command is a weighted blend of the user&#x27;s input through their assistive input device and the robot&#x27;s autonomous plan.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80dc-861e-fd885013cf6d" class="">This blend is controlled by a single parameter <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span><span>﻿</span></span>:</p></div><div style="display:contents" dir="auto"><figure id="27d36fd4-09d8-8099-87b6-f14e44c6cd2b" class="equation"><style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Command</mtext><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo>×</mo><mtext>(User Input)</mtext><mo>+</mo><mi>α</mi><mo>⋅</mo><mtext>Robot Autonomy</mtext></mrow><annotation encoding="application/x-tex">\text{Command}=(1−α)×\text{(User Input)}+\alpha \cdot \text{Robot Autonomy}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">Command</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(User Input)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">Robot Autonomy</span></span></span></span></span></span></div></figure></div><div style="display:contents" dir="auto"><ul id="27d36fd4-09d8-807a-afdb-cdd359504cf8" class="bulleted-list"><li style="list-style-type:disc"><style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">α=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span><span>﻿</span></span>: Fully tele-operated; the robot only executes the user&#x27;s raw commands</li></ul></div><div style="display:contents" dir="auto"><ul id="27d36fd4-09d8-80d0-8b1f-d6a82d099e17" class="bulleted-list"><li style="list-style-type:disc"><style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">α=1 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span>: Fully autonomous; the robot ignores the user&#x27;s input and executes its optimal plan</li></ul></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-80e2-8f5b-e0694da14501" class="">
</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8064-b017-c42c12eb84a5" class="">Our specific study uses angle disagreement between the user&#x27;s input vector and the robot&#x27;s final motion vector as a real-time proxy for the mismatch threatening SoA. We hypothesize that as the angle of disagreement increases, the user&#x27;s subjective sense of agency will decrease, and the in-task survey results intend to measure this prediction.</p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-80c9-9a59-f9e967a08678" class="">
</p></div><div style="display:contents" dir="auto"><hr id="28136fd4-09d8-80b0-b099-f7940200f726"/></div><div style="display:contents" dir="auto"><h1 id="27d36fd4-09d8-8058-a3a6-d8f4a9fa2276" class=""><mark class="highlight-orange">The Human-Robot Communication Layer</mark></h1></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80bf-b7fa-c55b0dbfb84d" class="">My role has been focused on building the interactive and communication system, the part that turns a human&#x27;s intention into a robot command and back again, using a web interface.</p></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-80c3-ae18-dc3fe599f65c" class="">1. The Human Interface </h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8050-a01f-c131f0128be7" class="">I was responsible for designing and building the frontend web application that serves as the  control panel for the robot arm movement.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8047-b3df-e4473f49f5fb" class="">I translated the functional requirements of the robotic movements, 3 degrees of rotation and 3 degrees of translation, into a visually clear control layout. I prioritized accessibility by implementing custom responsive CSS to create large, clearly spaced touch/click targets, optimizing the design for users who may rely on adaptive input devices or have reduced fine motor control. I built a hi-fi prototype using React that handles all user interaction logic, such as pressing and holding for continuous movement or quick tapping for discrete movement of the arm.</p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-80d5-a1d8-de6cf943af66" class="">
</p></div><div style="display:contents" dir="ltr"><figure id="27d36fd4-09d8-801c-a728-edf54f656a5d" class="image"><a href="Understanding%20Sense%20of%20Agency%20in%20Assistive%20Robotic/Screenshot_2025-09-28_at_11.35.34_PM.png"><img style="width:432px" src="images/reports/sense-of-agency/interface.png"/></a></figure></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-80e2-a979-c6acd001641a" class="">
</p></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-8041-9146-cb8e510dfe8b" class="">2. In-task Feedback Loop</h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-808b-8d03-e3b3fb250e85" class="">While the web interface was set up, we still had to combat the challenge of creating a low-latency communication bridge between the web app, which was on React, and the live robot control system, ROS. We wanted the movement inputs to be sent quickly and accurately to the robot, and have the robot send signals back to the web app for when to display a survey on the user’s screen: this would be to capture the user&#x27;s feeling of agency at intervals while they were performing a specific task.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80d2-a8cf-ef01e467cbb2" class=""><br/><strong>Note on ROS</strong></p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80cc-a8f0-f1e3b404382b" class="">ROS is the software framework that connects the different parts of the robot, like its motors, sensors, and planning logic. ROS is the central nervous system of the system. All communication between the web interface and the robot happens through ROS, specifically using “topics” or named data streams.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8028-80b6-fa411ede7fe5" class="">
</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-807a-95fb-eae4b98b66ea" class="">I designed and integrated an in-task survey component for the web app. This feature allows the system to pause the task and immediately capture the user&#x27;s feeling of agency via a 5-point scale. </p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8055-a9f6-d80abdece096" class="">
</p></div><div style="display:contents" dir="ltr"><figure id="27d36fd4-09d8-80e1-8109-c803f2c2ef72" class="image"><a href="Understanding%20Sense%20of%20Agency%20in%20Assistive%20Robotic/Screenshot_2025-09-28_at_11.35.12_PM.png"><img style="width:480px" src="images/reports/sense-of-agency/survey.png"/></a></figure></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-80e4-a45d-c8fd3fa274d1" class="">
</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80a5-bd83-d2540106e553" class="">To do this, I set up a communication pipeline for the robot arm and the web app. The web app is configured to subscribe to a ROS Topic that acts as an interrupt signal from the robot&#x27;s central logic. This ensures the survey pops up precisely at the moment of robotic intervention. The user&#x27;s response is then published back to the robot&#x27;s log for data collection in real time.</p></div><div style="display:contents" dir="auto"><h3 id="28536fd4-09d8-8076-8b1d-f3a55cdc79f0" class="">3. Task Design </h3></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-804e-8d09-fc2de8c00c3b" class="">To contextualize the task and gain insight into how sense of agency might feel outside of a standard lab setting, we developed a practical situation where users would have to make a cup of coffee: from placing a mug in the right position, to pouring water and instant coffee into it, and then adding sugar. </p></div><div style="display:contents" dir="auto"><p id="28636fd4-09d8-80c0-9762-db94a08539f4" class="">
</p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-809f-94de-f3d6e25c226d" class="">We intend to use this task in both the upcoming focus groups and in future public studies. The experimental conditions for the quantitative studies are designed as follows:</p></div><div style="display:contents" dir="auto"><ul id="28536fd4-09d8-80cd-aca2-dce8b6cb40c3" class="bulleted-list"><li style="list-style-type:disc">Trial Condition: The user performs half of the task using fully tele-operated control (<style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">α=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span></span><span>﻿</span></span>) to get the user familiar with operating the robot arm.</li></ul></div><div style="display:contents" dir="auto"><ul id="28536fd4-09d8-8027-91c7-c80bd6cedbc2" class="bulleted-list"><li style="list-style-type:disc">Control Condition: The user performs the other half of the task using predictive shared autonomy (where the robot&#x27;s input is automatically provided, representing a specific, non-user-adjustable <style>@import url('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex-swap.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">α</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span></span><span>﻿</span></span>).</li></ul></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8007-8d31-f28bb8f0568c" class="">
</p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8083-9bee-ca98b4c6e8eb" class="">The proof of concept for this task is shown with a demo video here, which is sped up: </p></div><div style="display:contents" dir="ltr"><figure id="28636fd4-09d8-807f-80f0-e72b3b41891d"><div class="source"><a href="https://drive.google.com/file/d/1tAV4tpi10pw9AMmG9-XC1nSNGLPHjS1J/view?usp=sharing">https://drive.google.com/file/d/1tAV4tpi10pw9AMmG9-XC1nSNGLPHjS1J/view?usp=sharing</a></div></figure></div><div style="display:contents" dir="auto"><hr id="28136fd4-09d8-8072-b75e-de7337c91bd2"/></div><div style="display:contents" dir="auto"><h1 id="27d36fd4-09d8-80a1-8644-fff9a9f75718" class=""><mark class="highlight-orange">Community Engagement </mark></h1></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-8054-8775-e3c495d05a44" class="">Outreach at Disability Pride</h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-8075-a9e0-eb14b4172c04" class="">We sought community feedback before formal data collection. We took our functional prototype to Disability Pride Pittsburgh to get feedback from individuals with mobility limitations about our project and assistive tech in general.</p></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80fa-84d7-fe0363bc5e22" class="">This outreach was about qualitative discovery, not data collection since we didn’t have IRB approval yet. I spoke with potential users and demonstrated operating the robot arm with a game controller, and observed those who wished to test out the arm and how they interacted with the interface. It was imperative to have people learn about and experience first-hand what we were working on to ensure our next steps have elements of co-design.</p></div><div style="display:contents" dir="auto"><h3 id="27d36fd4-09d8-80fe-82b1-e7667d3551db" class="">Next Steps</h3></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80d0-ad6a-eebcacbf9d50" class="">Currently, we are designing questions for the upcoming focus groups. These sessions are purely qualitative and will gather contextual feedback directly from people with upper mobility limitations. I designed a recruitment flyer for these upcoming sessions:<br/></p></div><div style="display:contents" dir="ltr"><figure id="27d36fd4-09d8-80e1-990f-f3900f891780" class="image"><a href="Understanding%20Sense%20of%20Agency%20in%20Assistive%20Robotic/focus_group_flyer.png"><img style="width:384px" src="images/reports/sense-of-agency/focus_group_flyer.png"/></a></figure></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-80f4-ada3-c4c7f5ada0d4" class="">The goal is to deeply understand the context of sense of agency in realistic environments. Our discussion topics include:</p></div><div style="display:contents" dir="auto"><ul id="27d36fd4-09d8-8083-b704-da6c4012a6ed" class="bulleted-list"><li style="list-style-type:disc">Tasks that vary by risk, need for privacy (like bathing), caregiver availability, and time-sensitivity (getting ready to go somewhere)</li></ul></div><div style="display:contents" dir="auto"><ul id="27d36fd4-09d8-802c-bc7d-f6a7807f629d" class="bulleted-list"><li style="list-style-type:disc">Open-ended questions about the balance between task success and feeling in control (sense of agency)</li></ul></div><div style="display:contents" dir="auto"><ul id="27d36fd4-09d8-8068-a455-f2e3d50d90d4" class="bulleted-list"><li style="list-style-type:disc">Questions that will guide design of assistive tech products in general, such as &quot;When the robot disagrees with you, what should it do? Is the answer contextual?&quot; Should it stop entirely, correct you, or give you a warning?”</li></ul></div><div style="display:contents" dir="auto"><p id="27d36fd4-09d8-807b-986a-e65e0a0a5830" class="">This step serves to ensure that our formal study design and experimental conditions reflect genuine user needs before we begin our quantitative work. This reflects the objective of our project: to create a more human-centered framework for shared control by incorporating feedback from the users that will be using these frameworks. </p></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8023-a8db-ce15632aa739" class="">
</p></div><div style="display:contents" dir="auto"><hr id="28536fd4-09d8-807d-9b7a-e31cd7811f54"/></div><div style="display:contents" dir="auto"><p id="28536fd4-09d8-8033-a4a5-ef4485869d79" class="">
</p></div></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>